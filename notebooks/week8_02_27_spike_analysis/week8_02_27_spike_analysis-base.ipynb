{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c97c20-2bd6-4596-a471-6e836df5dfe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"fa2b009b-f715-4093-94a6-d32a2ac59061\"></a>\n",
    "# Week 8: Walk and Spike Analysis\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1162b5e-c9f4-46c8-bb72-dfedbe9c6eab",
   "metadata": {
    "tags": []
   },
   "source": [
    "Hello All, \n",
    "\n",
    "Today we are going to be analyzing whole-cell patch clamp electrophysiology data. \n",
    "\n",
    "A bit of background.. \n",
    "\n",
    "I'm currently examining the effects of chronic morphine exposure on the ability for paraventricular nucleus of the thalamus (PVT)    to fire action potentials. \n",
    "    \n",
    "Experimentally, I'm probing this by holding cells in a Current-Clamped configuration and injecting depolarizing currents while measuring changes to the voltage. (this allows us to visualize action potentials. (Insert example trace of an action potential - illustrating that once the voltage passes a threshold of 0 mV you get action potentials). we will be analyzing the voltage response to a 100 pA current injection under 4 different context. \n",
    "    \n",
    "Unfortunately, (or perhaps fortunately for yall) my inital experiements were not designed with streamlined coding in mind. SO what i actually ended up doing was injecting varying current steps into a single cell, beginning at -200 pA and ending at +600 pA increasing by 100 pA increments. \n",
    "    \n",
    "So what is the goal for today?\n",
    "    \n",
    "    1. write a code to analyze relevant information from our data\n",
    "        relevant data:\n",
    "            a. number of spikes\n",
    "            b. Latency\n",
    "            c. interspike interval \n",
    "            d. frequency of spikes \n",
    "    2. once we have the frame work in place, lets write a code to streamline this process for us. that is, simply plug in a folder with all the data and have the code comb (WAlK) through each folder for the relevant information. \n",
    "    \n",
    "    Lets begin! :D "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641bb6c-d720-4806-96e8-94fbcaf6ceed",
   "metadata": {},
   "source": [
    "<a id=\"5f458303-534b-4959-be76-ea31a22e686e\"></a>\n",
    "# Examine example data file\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321c59c-56ca-480f-8d20-ae432ab1bece",
   "metadata": {},
   "source": [
    "First things first. the packages you will need \n",
    "\n",
    "we are going to be using \n",
    "\n",
    " os \n",
    " numpy as np\n",
    " scipy.signal import find_peaks\n",
    " matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203a539-421e-4af4-8a23-cfc9462a67e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8c75f-b261-4c72-9c65-fcf36e212410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Test = np.loadtxt('Data/Naive/Morphine/01232023_7.axgt', skiprows=1, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aba756-6ec7-4025-87df-c52bc28c2998",
   "metadata": {
    "tags": []
   },
   "source": [
    "A little bit about the data. Again it was not made with coding in mind (sorry). So lets get a handle on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd95c78-e652-467e-8990-d68fcf11104f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dffc7b7-b88e-43cd-9944-58152a01b995",
   "metadata": {},
   "source": [
    "If we look at the shape, we see that it has the shape of (50000, 6). This is becuase my experiment is 5 seconds long, sampled at 10 KHz. A depolarizing, (or Hyperpolarizing) current step was given at 1 second (or the 10000 recorded data point) and lasted for 1 whole seconds. Experiments were recorded using the program Axograph. the data it spits out is oraganized as follows. the first column is always time. We really only care about the 100 pA depolarizing current step, which is stored in the **fifth** column of the data matrix.\n",
    "\n",
    "Write a script to pull out our time variable and the data during the 100 pA depolarizing current step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c416bf-1aa2-4091-a1f6-3993f1d1e24d",
   "metadata": {},
   "source": [
    "<a id=\"3c061738-2f22-41f8-80bc-b5f5cd92e75e\"></a>\n",
    "## Exercise 1\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "write a script to pull out our time variable and the data during the 100 pA depolarizing current step and the plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29915bde-76a1-44e3-a203-71e63315c6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Answer \n",
    "\n",
    "#convert_to_mv = 10e10\n",
    "time = Test[:, 0]\n",
    "depo_pA = Test[:, 4]\n",
    "\n",
    "depo_pA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dd59d-17ad-4383-a7de-a9824771ea54",
   "metadata": {},
   "source": [
    "Great! So now we have our two relevant columns from our data. lets plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d0c75-068b-4737-8702-c1a7e84c6027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answer \n",
    "# Plot the data\n",
    "plt.plot(time, depo_pA, label='Depo_pA')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Voltage')\n",
    "plt.title('Plot of Time vs Depo_pA')\n",
    "#plt.xlim(.9,2.1)\n",
    "# Add legend\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb78d43-3107-4896-85c6-9279f82b6cdf",
   "metadata": {},
   "source": [
    "Heck YEAH! I did that experiment! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47018517-5e09-4273-8f7b-28cb9657d396",
   "metadata": {},
   "source": [
    "<a id=\"199baedf-e58f-49ae-951f-8292fcb7b927\"></a>\n",
    "## Spike number\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "So lets write some lines to get at our pertinant data beginning with the number of action potentials. Keep in mind that once a cells membrane potential (voltage) goes above 0, we can call that an action potential. \n",
    "\n",
    "Goal is to identify the number of spikes during the depolarizazion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82058064-c8b7-4b32-bfde-e8be6ae351da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the threshold\n",
    "threshold = 0\n",
    "\n",
    "# Call find_peaks\n",
    "peaks, _ = find_peaks(depo_pA, height=threshold)\n",
    "\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730996a6-5666-4766-8ea6-15ba608b376d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Answer\n",
    "\n",
    "# Set the threshold\n",
    "threshold = 0\n",
    "\n",
    "# Define the time range (between 1 and 2 seconds)\n",
    "start_time = 1\n",
    "end_time = 2\n",
    "\n",
    "# Find the indices within the specified time range\n",
    "time_indices = np.where((time >= start_time) & (time <= end_time))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483c1e6-8b18-44db-a2ac-6c41239d1281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Answer \n",
    "\n",
    "# Initialize a counter for the occurrences\n",
    "num_spike_events = 0\n",
    "\n",
    "# Iterate over the indices and count occurrences\n",
    "in_spike = False\n",
    "for idx in time_indices:\n",
    "    if depo_pA[idx] > threshold and not in_spike:\n",
    "        # Entering a spike event\n",
    "        in_spike = True\n",
    "        num_spike_events += 1\n",
    "    elif depo_pA[idx] <= threshold and in_spike:\n",
    "        # Exiting a spike event\n",
    "        in_spike = False\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of spike events between {start_time} and {end_time} seconds: {num_spike_events}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0cff50-03bb-452e-8316-b5b739d37134",
   "metadata": {},
   "source": [
    "For good measure, lets make sure that is actually picking up each AP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ee93d-99f8-443a-923d-91c1764b2f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data with peaks\n",
    "plt.plot(time, depo_pA, label='100 pA')\n",
    "plt.plot(time[peaks], depo_pA[peaks], 'r.', label='Peaks')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Voltage')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4aa54-b000-4134-b615-c79d932b6bd0",
   "metadata": {},
   "source": [
    "<a id=\"c6decc8e-a352-42fc-9939-a11e2e0838c5\"></a>\n",
    "## Exercise 2: Zoom in to stimuluation time\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Plot the data zoomed in only over the 1-sec stimulation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c98fd-334e-4941-a9e0-9eb2ecb4e4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answer\n",
    "\n",
    "# Plot the data with peaks\n",
    "plt.plot(time, depo_pA, label='100 pA')\n",
    "plt.plot(time[peaks], depo_pA[peaks], 'r.', label='Peaks')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Voltage')\n",
    "plt.legend()\n",
    "plt.xlim(1,1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023133d2-f8d7-4287-99dd-062846580066",
   "metadata": {},
   "source": [
    "##**DRUM SOLO**## FUCK YEAH! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7057f9-a515-4463-ac6f-8086780e2602",
   "metadata": {},
   "source": [
    "<a id=\"aed7aa2c-de3a-43c1-9540-aa6326c7d81b\"></a>\n",
    "## Calculating the latency\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa87f2-eba6-48b5-af97-86a56d61b542",
   "metadata": {},
   "source": [
    "Great! Now let's look at how long it took for the first spike to occur in relation to the start of the depolarizing step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b7520-04d7-4b5c-9449-e2c304bf01df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the first index where depo_pA exceeds the threshold\n",
    "above_threshold_indices = np.where(depo_pA > threshold)[0]\n",
    "\n",
    "if above_threshold_indices.size > 0:\n",
    "    # Get the first index where depo_pA exceeds the threshold\n",
    "    first_peak_index = above_threshold_indices[0]\n",
    "\n",
    "    # Calculate the latency to the first peak\n",
    "    latency_to_first_peak = time[first_peak_index] - start_time\n",
    "    \n",
    "\n",
    "    print(f'Latency to the first peak above threshold: {latency_to_first_peak} seconds')\n",
    "else:\n",
    "    print('No peak above threshold in the specified time range.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863d174-a948-4868-ab00-a82b753619e6",
   "metadata": {},
   "source": [
    "Gnarly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124f41e-f64c-4d4b-acd9-488908c6fa5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"7722053d-e985-4855-bc35-e76168e775f9\"></a>\n",
    "## Inter Spike interval (ISI)\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1bbd6-93db-4bb2-bb83-e0b38865f2b1",
   "metadata": {},
   "source": [
    "Another relavent piece of info is the time betweem spikes. we can easily calculate this with  ``np.diff`` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ada30-2673-413e-852b-392a2ec248ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"11921587-2bde-4b37-89ae-4b25dbfcb40c\"></a>\n",
    "## Exercise 3: Calculate the ISI\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70e421-cdec-481e-b017-5e87b69cb289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.diff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a8b2-e51c-4b04-b1b5-7f21ff9a996c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inter_spike_intervals = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0595ec3-22fa-4ff1-a21c-0ec48a5aa3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Answer \n",
    "\n",
    "# Calculate inter-spike intervals\n",
    "inter_spike_intervals = np.diff(time[peaks])\n",
    "inter_spike_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2b33c-db7d-4b4f-a4c8-9511edd6a314",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we want to look at the Frequency. that is the number of action potentials within the firing range. Its worth noting that while we are deplarizing for 1 second, these cells stop firing before the current step is over (Sometimes..). this is thought to be secondary to sodium channel inactivation Voltage-gated sodium channels open (activate) when the membrane is depolarized and close on repolarization (deactivate) but also on continuing depolarization by a process termed inactivation, which leaves the channel refractory, i.e., unable to open again for a period of time.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec2d32-a2c2-4cd8-88c9-eccbb86bb1ab",
   "metadata": {},
   "source": [
    "So to calculate the frequency we want to look at the number of events / the time from intiation to Na channel inactivation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ab45a-369e-41ef-a1b1-475bf4442dad",
   "metadata": {},
   "source": [
    "<a id=\"301e6d3a-35f7-47a9-9dbc-17886ef368c7\"></a>\n",
    "## Exercise 4: Calulate frequency\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8559c-3df9-434b-87c7-da864a3cfc97",
   "metadata": {},
   "source": [
    "There are two ways that come to mind to calculate the time to Na inactivation. (1) finding the time of the last peak or (2) taking the sum of all the ISIs. Is there a 3rd way yall can think of? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24955a-b8b9-4e09-a6f6-0d2809ba8bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Answer \n",
    "\n",
    "if num_spike_events > 0:\n",
    "    spike_frequency = num_spike_events / np.sum(inter_spike_intervals)\n",
    "else:\n",
    "    spike_frequency = np.nan\n",
    "    \n",
    "spike_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d5d34-9770-462f-86f2-3d2b773dc41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Answer \n",
    "\n",
    "if above_threshold_indices.size > 0:\n",
    "    # Get the last index where depo_pA exceeds the threshold\n",
    "    last_peak_index = above_threshold_indices[-1]\n",
    "\n",
    "    # Calculate the latency to the last peak\n",
    "    latency_to_last_peak = time[last_peak_index] - start_time\n",
    "\n",
    "    print(f'Latency to the last peak above threshold: {latency_to_last_peak} seconds')\n",
    "else:\n",
    "    print('No peak above threshold in the specified time range.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5134a8-77ca-44ab-8f26-c4962d52a496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Frequency = num_spike_events/latency_to_last_peak \n",
    "Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36594937-9e8a-4731-b790-0b64c68cb715",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"c3111e33-7cfa-4eea-b932-157d44f41158\"></a>\n",
    "# Iterate through file\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32eebf4-4f49-46bd-8a1b-6e96a4ff362d",
   "metadata": {
    "tags": []
   },
   "source": [
    "First some info on how the data is oragnaized.\n",
    "\n",
    "Data exists as txt files (.agxt) in the folder [Data]. this folder has two more folders repesenting two treatment groups [Naive, MTA]. each folder has TWO MORE subfolders [Morphine, NLX]. So we want to record all the data and give them the label of what folder/subfolder it is being analyzed from.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9227f-bcae-485e-89aa-89c8c9fecb12",
   "metadata": {},
   "source": [
    "Lets take the example weve been looking at today and get its contextual information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7931a4-bbc4-43c4-ac82-1bc1d2b6da47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_file='Data/Naive/Morphine/01232023_7.axgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d163d21-8c38-4d86-b933-9e825ec89337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_parts = example_file.split('/')\n",
    "f = path_parts[3]\n",
    "parent = path_parts[2]\n",
    "grandparent = path_parts[1]\n",
    "print(f\"file: {f}\")\n",
    "print(f\"condition (parent folder): {parent}\")\n",
    "print(f\"animal group (grandparent folder): {grandparent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a8b11-0eb4-4e71-a68f-b7032cfa6a38",
   "metadata": {},
   "source": [
    "Great! we've gotten the components of all we want to do to our data. now let's make it do that through all of our files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed5e87-8e5a-4507-8f3d-fdeb4d4c4504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "df_files = pd.DataFrame()\n",
    "\n",
    "startpath='Data'\n",
    "counter = 0\n",
    "for root, dirs, files in os.walk(startpath):\n",
    "    for f in files:\n",
    "        if f.endswith('axgt'):\n",
    "            full_file = Path(root, f)\n",
    "            # print(full_file.parents[2])\n",
    "            # path_parts = root.split('/')\n",
    "            parent = full_file.parents[0]\n",
    "            grandparent = full_file.parents[1]\n",
    "            df_files.loc[counter,'filepath']=full_file\n",
    "            df_files.loc[counter,'group']=grandparent.name\n",
    "            df_files.loc[counter,'condition']=parent.name\n",
    "            df_files.loc[counter,'file']=f\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "df_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e71fb-a496-42fe-b561-2003fa656013",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"9826140c-9759-448b-abaa-a2b202776640\"></a>\n",
    "## Exercise 5: Compute statistics for all files\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Write code that iteraties through each row of `df_files`, measures spike times and computes the spikes statistics. Save the spike count, spike frequency and time to last spike in columns `spike_count`, `spike_frequency` and `time_to_last_spike`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0d6df-32af-41d2-a112-4f818a00c5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answer\n",
    "\n",
    "for i, r in df_files.iterrows():\n",
    "    print(\"Processing:\", i, r['filepath'])\n",
    "\n",
    "    data = np.loadtxt(r['filepath'], skiprows=1, delimiter='\\t')\n",
    "    \n",
    "    # Extract time and data for analysis\n",
    "    time = data[:, 0]\n",
    "    experiment_data = data[:, 4] \n",
    "    \n",
    "    # Analysis results for: number of spikes/frequency/time to last spike  \n",
    "    threshold = 0\n",
    "    peaks, _ = find_peaks(experiment_data, height=threshold)\n",
    "\n",
    "    \n",
    "    inter_spike_intervals = np.diff(peaks)\n",
    "    num_spike_events = len(peaks)\n",
    "    \n",
    "    if num_spike_events > 0:\n",
    "        spike_frequency = num_spike_events / np.sum(inter_spike_intervals)\n",
    "    else:\n",
    "        spike_frequency = np.nan\n",
    "    \n",
    "    onset_time = 1\n",
    "    time_to_last_spike = peaks.max() if num_spike_events > 0 else None\n",
    "\n",
    "    df_files.loc[i,'spike_count']=num_spike_events\n",
    "    df_files.loc[i,'spike_frequency']=spike_frequency\n",
    "    df_files.loc[i,'time_to_last_spike']=time_to_last_spike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621498ed-ed0d-4de8-ab3f-6f4a24d6d8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_files.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7c682-ba6a-4ea1-bc39-13ff144349dd",
   "metadata": {},
   "source": [
    "Lastly, we can move our results to a .csv for export and use the fancy statistics software we already pay for to analyze the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733e51b-926e-4f90-8726-63cf222cdfc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_files.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308b4ee-9d94-495c-8964-df7189160f10",
   "metadata": {},
   "source": [
    "ALTERNATIVELY: we need to tell it where we are getting out data from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e0b50-2323-4a1c-875e-ba8277b2fef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the top-level folder path ('Data' folder)\n",
    "top_folder_path = 'Data' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ba5d1b-5990-4447-beca-e3fab824ce87",
   "metadata": {},
   "source": [
    "So to start lets define the columns of data we want to fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac88d9b-8e8f-4a38-88ef-f23228630bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_data(top_folder_path):\n",
    "    # Initialize lists to store results\n",
    "    file_names = []\n",
    "    parent_folders = []  \n",
    "    subfolders = []  \n",
    "    num_spike_events_list = []\n",
    "    inter_spike_intervals_list = []\n",
    "    spike_frequency_list = []\n",
    "    time_to_last_spike_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d336699-eb2b-4808-a293-2346ee530d8b",
   "metadata": {},
   "source": [
    "Once we set the path for the code to follow we just got to put the code we made above into a for loop and allow it to iterate through all our data. additonally we will want to make it spit all that data into a spreadsheet so I.. i mean we can stop coding and move the data to another software we are aready paying for like prism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579a852-fe69-4a29-953b-7d415ed54365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answer \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_data(top_folder_path):\n",
    "    # Initialize lists to store results\n",
    "    file_names = []\n",
    "    parent_folders = []  \n",
    "    subfolders = []  \n",
    "    num_spike_events_list = []\n",
    "    inter_spike_intervals_list = []\n",
    "    spike_frequency_list = []\n",
    "    time_to_last_spike_list = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through all subfolders within the top folder\n",
    "    for root, dirs, _ in os.walk(top_folder_path):\n",
    "        # Check if the current subfolder is a 'morphine' or 'NLX' folder\n",
    "        if os.path.basename(root) in ['Morphine', 'NLX']:\n",
    "            # Get the parent folder (Naive or MTA)\n",
    "            parent_folder = os.path.basename(os.path.dirname(root))\n",
    "            # Get the subfolder (morphine or NLX)\n",
    "            subfolder = os.path.basename(root)\n",
    "\n",
    "            # Iterate through all files in the current folder\n",
    "            for file_name in os.listdir(root):\n",
    "                if file_name.endswith('.axgt'):\n",
    "                    # Load data from the file\n",
    "                    file_path = os.path.join(root, file_name)\n",
    "                    data = np.loadtxt(file_path, skiprows=1, delimiter='\\t')\n",
    "\n",
    "                    # Extract time and data for analysis\n",
    "                    time = data[:, 0]\n",
    "                    experiment_data = data[:, 4]  # Change the column index as needed\n",
    "\n",
    "                    # Analysis results for: number of spikes/frequency/time to last spike  \n",
    "                    threshold = 0\n",
    "                    peaks, _ = find_peaks(experiment_data, height=threshold)\n",
    "\n",
    "                    num_spike_events = len(peaks)\n",
    "                    inter_spike_intervals = np.diff(time[peaks])\n",
    "\n",
    "                    if num_spike_events > 0:\n",
    "                        spike_frequency = num_spike_events / np.sum(inter_spike_intervals)\n",
    "                    else:\n",
    "                        spike_frequency = np.nan\n",
    "\n",
    "                    onset_time = 1\n",
    "                    time_to_last_spike = time[peaks[-1]] - onset_time if num_spike_events > 0 else None\n",
    "\n",
    "                    # Add results to lists\n",
    "                    file_names.append(file_name)\n",
    "                    parent_folders.append(parent_folder)  \n",
    "                    subfolders.append(subfolder)  \n",
    "                    num_spike_events_list.append(num_spike_events)\n",
    "                    inter_spike_intervals_list.append(inter_spike_intervals)\n",
    "                    spike_frequency_list.append(spike_frequency)\n",
    "                    time_to_last_spike_list.append(time_to_last_spike)\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "    # Create a spreadsheet (CSV file) with the results\n",
    "    output_directory = \"output\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    output_file_path = os.path.join(output_directory, 'analysis_results.csv')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'File Name': file_names,\n",
    "        'Parent Folder': parent_folders,  \n",
    "        'Subfolder': subfolders,  \n",
    "        'Number of Spike Events': num_spike_events_list,\n",
    "        'Inter-Spike Intervals': inter_spike_intervals_list,\n",
    "        'Spike Frequency (Hz)': spike_frequency_list,\n",
    "        'Time to Last Spike': time_to_last_spike_list\n",
    "    })\n",
    "\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "    print(f\"Number of times the loop ran: {count}\")\n",
    "\n",
    "# The top-level folder path ('Data' folder)\n",
    "top_folder_path = 'Data'  \n",
    "analyze_data(top_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f45744-3d4a-4549-a0ff-35d6238d44bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "If we are left doing the rest of the analysis on python, the next step will be going into the newly developed data files and pulling out the relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adb333-da45-441d-b126-39bbff9cf878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a533beb-0adc-426f-a227-9e4735b18eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
