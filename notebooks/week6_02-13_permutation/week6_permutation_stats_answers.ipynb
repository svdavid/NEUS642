{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<a href=\"#Overview\"></a>\n# Overview\n* <a href=\"#7715e1f2-2926-42a1-8cc3-1cbf1acc905a\">Permutation tests</a>\n  * <a href=\"#1cd64aa5-c17e-48d1-aa7b-0fc110af6be0\">How does arousal impact neural coding in auditory cortex?</a>\n    * <a href=\"#ab4b7120-4dd9-41bd-aa5c-4f7d33f9fa61\">Function list</a>\n* <a href=\"#ab922e84-3211-4c9f-a9a5-d029c8ea6872\">Load the data</a>\n  * <a href=\"#dc42f280-ab26-406e-83be-2d636f45a285\">Exercise 1: load the correct files</a>\n    * <a href=\"#8533990e-736b-4ee2-b88e-18c836be157b\">Get to know your data</a>\n* <a href=\"#f531f4ce-af78-4bdf-8155-883771def50d\">Plot state-dependent PSTHs</a>\n  * <a href=\"#c226298d-1768-4018-ba0d-a8eeb8bd037e\">Exercise 2: compute mean pupil per trial</a>\n  * <a href=\"#d2b9d1e5-ff9c-4358-990c-ed6649f78e8f\">Exercise 3: compute average response in each pupil group</a>\n    * <a href=\"#c0f1b58e-68b5-4588-be4d-fd075de1e3b2\">Exercise 4: fix the x axis</a>\n* <a href=\"#13b7af37-6dc3-486e-ad28-212ac87d7a79\">Comparing mean evoked spike rate</a>\n  * <a href=\"#4f094be8-7523-4fbb-b6cd-b92a4bce69b7\">Exercise 5: compute mean evoked rate on each trial</a>\n  * <a href=\"#aee3912b-3435-4741-9e55-29e48c2806da\">Exercise 6: compare response histograms</a>\n* <a href=\"#a623b812-038c-45d8-b90d-b9761e91faaf\">Permute!</a>\n  * <a href=\"#12d44766-1253-4834-9c36-c1e786bc668f\">Exercise 7: do the shuffle</a>\n  * <a href=\"#3cf0469f-d231-4dae-baec-c070bb0ba92d\">Exercise 8: multiple permutations</a>\n* <a href=\"#e0585c21-27c5-4c6e-93e0-11b01825991d\">Write a function to save time and space</a>\n  * <a href=\"#8e91c3c6-8016-4181-aff6-47f0687ed4b7\">Exercise 9: write a permutation test function</a>\n* <a href=\"#6568c72a-e3f7-44b3-90a5-42f764499447\">Permutation test for an arbitrary measurement</a>\n  * <a href=\"#317812bc-5e59-4a28-a6c9-69df0c6b7946\">Correlation coefficient</a>\n  * <a href=\"#9ab41349-5145-4fba-850e-f32a48f134f3\">Generate a custom metric function</a>\n  * <a href=\"#a48a1233-3876-4811-a1a1-b334b11a5757\">Exercise 10: custom correlation coefficient function</a>\n* <a href=\"#78c5bbbe-3a72-4113-ac99-d7336804899a\">Existing resources for permutation statistics</a>"}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"7715e1f2-2926-42a1-8cc3-1cbf1acc905a\"></a>\n# Permutation tests\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "<a id=\"1cd64aa5-c17e-48d1-aa7b-0fc110af6be0\"></a>\n## How does arousal impact neural coding in auditory cortex?\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "It is well-known that evoked spiking responses of neurons in sensory cortex are variable from trial to trial. Put another way, the same neuron will respond with different numbers of spikes to repeated presentations of identical sensory stimuli. Recently, one source of trial-to-trial variability that has been identified is arousal, as measured by pupil size. This notebooks illustrates analysis of how pupil-indexed arousal affects neural spiking, using data from Schwartz et al. <i>J Neurophys.</i> 2020.\n", "\n", "To study this problem, we record spiking activity from one or more single neurons in ferret auditory cortex while repeatedly presenting the same natural vocalization and using IR video to continuously measure pupil size. Here's a recording of pupil size from one experiment. Can you see where the experimenter presented an unexpected stimulus to \"wake up\" the animal?\n", "\n", "<p style=\"text-align: center;\"><img src=\"images/pupil_method.jpeg\" alt=\"drawing\" width=\"500\"/></p>\n", "\n", "Here is activty of a neuron recorded during this experiment that appears to be modulated by changes in pupil. The sound spectrogram is plotted at the top, with time-ordered raster in the middle. The same data, but with rows sorted by pupil size, appears at the bottom.\n", "\n", "<p style=\"text-align: center;\"><img src=\"images/pupil_example_raster.jpeg\" alt=\"drawing\" align=\"center\" width=\"500\"/></p>\n", "\n", "Today, we will use basic stastical methods for quantifying if and how pupil size impacts spiking activity. An important aspect of this presentation is appreciating that traditional statistical methods assuming Gassian (bell curve-shaped) data distributions, don't necessarily apply to neural spiking data. Instead, we employ permutation methods, which are robust to non-Gaussian data. As we get started, we'll also practice some other basic approaches to manipulating and visualizing reshaping numpy arrays."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"ab4b7120-4dd9-41bd-aa5c-4f7d33f9fa61\"></a>\n### Function list\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Numpy\n", "* `np.loadtxt`\n", "* `np.flatten`\n", "* `np.transpose`\n", "* `np.sqrt`\n", "* `np.std`\n", "* `np.stack`\n", "* `np.random.permutation`\n", "* `np.corrcoef`\n", "\n", "Matplotlib (these are not central to today's presentation but are good to know about).\n", "* `plt.subplots`\n", "* `plt.errorbar`\n", "* `plt.hist`\n", "\n", "Scipy\n", "* `scipy.stats.wilcoxon`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"ab922e84-3211-4c9f-a9a5-d029c8ea6872\"></a>\n# Load the data\n<a href=\"#Overview\">Return to overview</a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First, import the requisite libraries. You should already have all these installed in your Anaconda environment."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import scipy.stats as ss\n", "import os.path"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"dc42f280-ab26-406e-83be-2d636f45a285\"></a>\n## Exercise 1: load the correct files\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Data from a few neurons has been stored in `csv` files in the `data/` subdirectory. See if you can find the files containing spike and pupil data for neuron `eno052d-a1`. Use the numpy `loadtxt` command to read them in. Load the spike data into an array `spikes` and pupil data into `pupil`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "spikes = np.loadtxt('data/eno052d-a1_spikes.csv', delimiter=\",\")\n", "pupil = np.loadtxt('data/eno052d-a1_pupil.csv', delimiter=\",\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you loaded correctly, you should now see that the arrays contain the spikes count or pupil size, respectively. There are 55 samples per trial and 120 trials."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(spikes.shape)\n", "print(pupil.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A couple notes about the data. The matrices record the data in the order they were collected. Sampling is 10 Hz, so each data point reflects the number of spikes or pupil size during a 100 ms period. Consistent with the figure above, each trial consists of a 2-sec pre-stimulus silent period, 3 seconds of sound, 0.5-sec post-stimulus silence. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"8533990e-736b-4ee2-b88e-18c836be157b\"></a>\n### Get to know your data\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "First off, a few sanity checks. How many 10-Hz samples should we expect for trials of this length? We use `fs`, a traditional variable name from Matlab, to record the sampling rate, a.k.a., the number of samples per second in digially stored signal. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fs = 10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "(2 + 3 + 0.5) * fs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And does the data make sense? Let's see what the time series data look like over the course of the entire experiment. We'll use a couple new commands. What does `transpose` do? What does `flatten` do?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["a = np.array([[1,3,5],\n", "              [2,4,6]])\n", "print(a)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(a.flatten())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(a.transpose())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(a.transpose().flatten())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So you see, `flatten` stacks all the **rows** of a matrix together into a vector. `transpose` flips the rows and columns so that `flatten` can operate correctly when trials are in the columns. Let's apply it to the data:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Transposed shape:\", pupil.transpose().shape)\n", "print(\"Stretched out shape:\", pupil.transpose().flatten().shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pupil_flat = pupil.transpose().flatten()\n", "spikes_flat = spikes.transpose().flatten()\n", "\n", "# remember the arange function?\n", "# number of samples divided by fs gives you time of each sample in sec.\n", "t = np.arange(len(pupil_flat)) / fs  \n", "\n", "print(\"Total number of samples:\", len(pupil_flat))\n", "print(\"Total data sec:\", np.max(t))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Why is the duration not 660 sec?\n", "\n", "Now we can just plot a single vector for each signal. Note the use of `subplots` with the `sharex` option to make things line up nicely in a single figure."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["f,ax=plt.subplots(nrows=2, ncols=1, figsize=(10,3), sharex=True)\n", "ax[0].plot(t,pupil_flat)\n", "ax[0].set_ylabel('pupil size')\n", "\n", "ax[1].plot(t,spikes_flat)\n", "ax[1].set_ylabel('spikes')\n", "ax[1].set_xlabel('time (sec)');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Just for kicks, what does it look like if you forget to transpose before flattening?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Hopefully it's pretty clear from this quick analysis that spike rate varies with pupil size."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"f531f4ce-af78-4bdf-8155-883771def50d\"></a>\n# Plot state-dependent PSTHs\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Now we want to get a more quantitative sense of the pupil effects. A simple way to do this is to divide the spike data into half, between trials when pupil is large and when it is small. So a few steps:\n", "\n", "* identify trials when pupil is smaller vs. larger than the median\n", "* compute the average peri-stimulus time histogram (PSTH, also know as average time-varying response) for the two groups of trials.\n", "* plot the two PSTHs on top of each other."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"c226298d-1768-4018-ba0d-a8eeb8bd037e\"></a>\n## Exercise 2: compute mean pupil per trial\n<a href=\"#Overview\">Return to overview</a>\n", "Create a new array, called `mean_pupil_per_trial` that contains the mean value of the pupil on each trial. Hint: This should have the same length as the number of trials. What's the median pupil size?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# Answer\n", "mean_pupil_per_trial = np.mean(pupil, axis=0)\n", "mean_pupil_per_trial.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We're interested in group the data based on the median. This is a convenient way to divide it into two equal-sized groups. Remember how to do that? Note that the units of pupil (size in pixels) are arbitrary."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pupil_median = np.median(mean_pupil_per_trial)\n", "pupil_median"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's see if the median makes sense. We can generate a quick plot using things we learned in previous weeks."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.hist(mean_pupil_per_trial)\n", "plt.axvline(pupil_median, color='r')\n", "plt.xlabel('pupil size')\n", "plt.ylabel('number of trials');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"d2b9d1e5-ff9c-4358-990c-ed6649f78e8f\"></a>\n## Exercise 3: compute average response in each pupil group\n<a href=\"#Overview\">Return to overview</a>\n", "Now use `mean_pupil_per_trial` to mask out small and large pupil trials and save the results into `pupil_small_mean` and `pupil_large_mean`, respectively.  Remember how to mask?  eg, `A[x>b,:]` will select the rows from array `A` where values in `x` are greater than some threshold `b`. The size of x has to be the same as the number of rows in `A`. Sanity check: how many trials are used to compute each PSTH?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "pupil_big_psth = np.mean(spikes[:,mean_pupil_per_trial>pupil_median], axis=1)\n", "pupil_small_psth = np.mean(spikes[:,mean_pupil_per_trial<=pupil_median], axis=1)\n", "\n", "np.sum(mean_pupil_per_trial>pupil_median), np.sum(mean_pupil_per_trial<=pupil_median),"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note: To make sure you use all the data, you might use an `<=` rather than `<`, just in case some trials match the median exactly. You need to be careful, though, as this can generate groups of different sizes."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now it's pretty straightfoward to plot the data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.plot(pupil_small_psth, label='small')\n", "plt.plot(pupil_big_psth, label='big')\n", "plt.legend();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"c0f1b58e-68b5-4588-be4d-fd075de1e3b2\"></a>\n### Exercise 4: fix the x axis\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Oops. I forgot to label the x axis in a way that will make sense to a normal human. Remember how to generate a time vector so that the plot shows time from stimulus onset?  Remember, there's a 2-second pre-stimulus silence. Also, what are the units on the y-axis? Remember how to convert them to spikes per second?\n", "\n", "Bonus: consider also providing information about what is big or small."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "pre_trial_sec = 2\n", "t = np.arange(len(pupil_small_psth))/fs - pre_trial_sec\n", "\n", "plt.figure()\n", "plt.plot(t, pupil_small_psth*fs, label='pupil <= median')\n", "plt.plot(t, pupil_big_psth*fs, label='pupil > median')\n", "plt.xlabel('time from stimulus onset (s)')\n", "plt.ylabel('spike/sec')\n", "plt.legend();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"13b7af37-6dc3-486e-ad28-212ac87d7a79\"></a>\n# Comparing mean evoked spike rate\n<a href=\"#Overview\">Return to overview</a>\n", "So the response does seem a lot strong when pupil is large. Now let's confirm it with a permutation test!\n", "* compute mean evoked spike rate on each trial\n", "* compare the distribution of single-tral responses between groups."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"4f094be8-7523-4fbb-b6cd-b92a4bce69b7\"></a>\n## Exercise 5: compute mean evoked rate on each trial\n<a href=\"#Overview\">Return to overview</a>\n", "What was the reponse on each trial?  Slice out the time bins in `spikes` when sound was playing on each trial (remember, 2-sec pre-stimulus silence, 0.5-sec post-stimulus silence) to produce a variable `response` with the mean evoked rate per trial. \n", "\n", "Then generate two vectors: `response_small` and `response_large`, which contain the mean response on small and large pupil trials, respectively. Remember to mulitply the response by `fs` to get units of spikes/sec! How long is each vector?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "pre_stimulus_bins = int(2 * fs)\n", "post_stimulus_bins = int(0.5 * fs)\n", "response = spikes[pre_stimulus_bins:-post_stimulus_bins,:].mean(axis=0) * fs\n", "\n", "response_small = response[mean_pupil_per_trial<=pupil_median]\n", "response_large = response[mean_pupil_per_trial>pupil_median]\n", "response_small.shape, response_large.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can compute the mean response in each condition (remember `np.round`?):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.round(response_small.mean(),3), np.round(response_large.mean(),3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And for statistcal purposes, a simple quanity to think about is the mean difference:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mean_response_difference = np.mean(response_large) - np.mean(response_small)\n", "mean_response_difference"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, so spike rate is a lot higher on large-pupil trials. \n", "\n", "One way people traditionally compare distributions is by their mean and standard error. \"Standard error on the mean\" (SEM) is the standard deviation divided by the square root of the number of samples."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["T = len(response_small)\n", "mean_small = np.mean(response_small)\n", "sem_small = np.std(response_small)/np.sqrt(T)\n", "mean_large = np.mean(response_large)\n", "sem_large = np.std(response_large)/np.sqrt(T)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If the error bars don't overlap, then the means are significantly different with p<0.05. Notice that matplotlib has a convenient `errorbar` function. Take a look at the docs if you want to learn more."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.errorbar([1,2],[mean_small, mean_large], [sem_small, sem_large]);\n", "plt.xticks([1,2],['small','large'])\n", "plt.ylabel('mean response (spk/s)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But this can be deceptive. Let's try the same comparison for the spontaneous spike rate. Can you copy/modify code from above to compute the mean spont rate during the 2 seconds before each stimulus onset? Remember to scale by `fs`!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "spont = spikes[:pre_stimulus_bins,:].mean(axis=0) * fs\n", "\n", "spont_small = spont[mean_pupil_per_trial<=pupil_median]\n", "spont_large = spont[mean_pupil_per_trial>pupil_median]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now what do mean +/- SEM look like for those data?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["T = len(response_small)\n", "mean_small = np.mean(spont_small)\n", "sem_small = np.std(spont_small)/np.sqrt(T)\n", "mean_large = np.mean(spont_large)\n", "sem_large = np.std(spont_large)/np.sqrt(T)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.errorbar([1,2],[mean_small, mean_large], [sem_small, sem_large]);\n", "plt.xticks([1,2],['small','large'])\n", "plt.ylabel('mean spont rate (spk/s)');\n", "mean_spont_difference = mean_large-mean_small\n", "mean_spont_difference"]}, {"cell_type": "markdown", "metadata": {}, "source": ["They're not overlapping either. Hmm. The PSTH plot does suggest that the spont rate is *slightly* higher on large pupil trials (see above). But is it real? \n", "\n", "First let's look at the single-trial data in more detail."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We've looked as histograms, but what if we want to compare histograms from two different groups?  `np.stack` can be used to combine two length-$N$ vectors into an $N \\times 2$ matrix."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["a = np.array([1,1,2,2,2,3,3,5])\n", "b = np.array([2,3,4,4,4,5,5,6])\n", "data = np.stack((a,b), axis=1)\n", "print(data)\n", "plt.hist(data);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"aee3912b-3435-4741-9e55-29e48c2806da\"></a>\n## Exercise 6: compare response histograms\n<a href=\"#Overview\">Return to overview</a>\n", "Use `np.stack` and `plt.hist` to compare the two response distributions. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "data = np.stack([response_small, response_large], axis=1)\n", "plt.hist(data);\n", "plt.xlabel('response');\n", "plt.ylabel('number of trials');\n", "plt.legend(('small','large'));"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["These look pretty different. Unlikely that they were produced by chance. Now the same for spont rate:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.stack([spont_small, spont_large], axis=1)\n", "plt.hist(data);\n", "plt.xlabel('spont rate');\n", "plt.ylabel('number of trials');\n", "plt.legend(('small','large'));"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Is this real? Or could there just have been a few high-spont rate trials by change. This \"heavy tailed\" distribution is a classic deviation from a Gaussian distribution. The small number of large, asymetric values makes the mean of the large pupil condition large."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"a623b812-038c-45d8-b90d-b9761e91faaf\"></a>\n# Permute!\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Numpy has a bunch of tools for generating random numbers. A convenient funciton for today is `permutation`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["a=np.arange(10)\n", "np.random.permutation(a)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"12d44766-1253-4834-9c36-c1e786bc668f\"></a>\n## Exercise 7: do the shuffle\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "We want to randomly shuffle the trials included in the small and large pupil groups. An easy wey to do this is to create a permuted copy of `mean_pupil_per_trial`. Call it `shuffled_pupil`. Now recompute the reponse for \"small\" and \"large\" groups (`response_small_shuffled` and `response_large_shuffled`). Compute the mean response difference between groups and store it in `mean_response_difference`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "shuffled_pupil = np.random.permutation(mean_pupil_per_trial)\n", "\n", "response_small_shuffled = response[shuffled_pupil<=pupil_median]\n", "response_large_shuffled = response[shuffled_pupil>pupil_median]\n", "mean_response_difference_shuffled = np.mean(response_large_shuffled) - np.mean(response_small_shuffled)\n", "mean_response_difference_shuffled\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For fun, let's plot a histogram of the shuffled data. The shuffled respone distributions are not identical, but they're clearly much more similar than the real data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.stack([response_small_shuffled, response_large_shuffled], axis=1)\n", "plt.hist(data);\n", "plt.xlabel('response');\n", "plt.ylabel('number of trials');\n", "plt.legend(('small','large'));\n", "plt.title('Shuffled pupil comparison')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It's important to note that `permutation` is meant to be random. It's supposed to generate a different distribution each time you run it. Try running the two cells above a few times to see how the plot changes."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"3cf0469f-d231-4dae-baec-c070bb0ba92d\"></a>\n## Exercise 8: multiple permutations\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Let's repeat the permutation N=100 times. Write a `for` loop, where on each loop you permute `mean_pupil_per_trial` and compute a new shuffled mean difference between median groups. Save all these means in a length-100 vector `shuffled_distribution`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "N=100\n", "shuffled_distribution = np.zeros(N)\n", "for i in range(N):\n", "    shuffled_pupil = np.random.permutation(mean_pupil_per_trial)\n", "    response_small_shuffled = response[shuffled_pupil<=pupil_median]\n", "    response_large_shuffled = response[shuffled_pupil>pupil_median]\n", "    shuffled_distribution[i] = np.mean(response_large_shuffled) - np.mean(response_small_shuffled)\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, we plot a histogram of the shuffled differeneces. Don't you love histograms?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.hist(shuffled_distribution, label='shuffled')\n", "plt.axvline(mean_response_difference, color='r', label='actual')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Just to be totally unbiased, we might not want to make assumptions about which condition (big or small pupil) should be larger. In that case, we want to perform a two-tailed test. Intuitively, this means considering the absolute value of the relevant numbers:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.hist(np.abs(shuffled_distribution), label='shuffled')\n", "plt.axvline(np.abs(mean_response_difference), color='r', label='actual')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Still pretty obvious that the actual mean difference was not generated by chance, right?\n", "\n", "Now we can calculate a p-value directly! $p$ is the probability that the actual mean difference was generated by the shuffled distribution. Let's stick with a \"two-tailed\" test, which tests how likely the **absolute** value of the mean was larger than the actual value. Note that we have to include the actual value in this comparison, so that $p$ is never exactly zero. Thus we `append` the actual measure to the shuffled distribution before measuring p."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["effective_distribution = np.append(shuffled_distribution, mean_response_difference)\n", "\n", "total_N = len(effective_distribution)\n", "greater_equal_N = np.sum(np.abs(effective_distribution) >= np.abs(mean_response_difference))\n", "p = greater_equal_N / total_N\n", "p"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's try it for the spont data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "N=100\n", "shuffled_distribution = np.zeros(N)\n", "for i in range(N):\n", "    shuffled_pupil = np.random.permutation(mean_pupil_per_trial)\n", "    spont_small_shuffled = spont[shuffled_pupil<=pupil_median]\n", "    spont_large_shuffled = spont[shuffled_pupil>pupil_median]\n", "    shuffled_distribution[i] = np.mean(spont_large_shuffled) - np.mean(spont_small_shuffled)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.hist(np.abs(shuffled_distribution), label='shuffled')\n", "plt.axvline(np.abs(mean_spont_difference), color='r', label='actual')\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["effective_distribution = np.append(shuffled_distribution, mean_spont_difference)\n", "\n", "total_N = len(effective_distribution)\n", "greater_equal_N = np.sum(np.abs(effective_distribution) >= np.abs(mean_spont_difference))\n", "p = greater_equal_N / total_N\n", "p\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, no such luck with spont."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"e0585c21-27c5-4c6e-93e0-11b01825991d\"></a>\n# Write a function to save time and space\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "This permutation code is cool, but a bit cumbersome to copy and paste all the time. Let's make a compact function that performs the permutation test.  You remember about functions from week 1? "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_sum(a,b):\n", "    \"\"\"\n", "    compute the sum of two numbers\n", "    inputs:\n", "       a, b: numbers\n", "    output:\n", "       c: the sum of a and b\n", "    \"\"\"\n", "    c = a+b\n", "    return c"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["compute_sum(1,2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that the function includes a \"docstring\", bounded by \"\"\" and \"\"\" immediately below the `def`. What happens if I look for help?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["compute_sum?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We want a function that we can pass our two distributions, `response_small` and `response_large`, and get back a $p$ value telling us how likely they are to have different means.\n", "\n", "To make the function more general purpose, let's figure out a what to permute without any knowledge of pupil size. How do we do that? We can simply append the distributions together, shuffle, and split the shuffled distribution in half. Do you get what the slicing is doing when you create the two shuffled distributions?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_data = np.append(response_small, response_large)\n", "s = np.random.permutation(all_data)\n", "response_small_shuffled = s[:len(response_small)]\n", "response_large_shuffled = s[len(response_small):]\n", "response_small_shuffled.shape, response_large_shuffled.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"8e91c3c6-8016-4181-aff6-47f0687ed4b7\"></a>\n## Exercise 9: write a permutation test function\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Write a function, `my_permutation_test`. Given two distributions, `a` and `b`, and a permutation count `N`, perform `N` shuffles, count the number of times the shuffled absolute difference is greater than the actual absolute difference, and return p. Bonus: Provide a docstring!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "def my_permutation_test(a,b,N=100):\n", "    \"\"\"\n", "    use permutation to test whether the means of a and b are significantly different.\n", "    inputs:\n", "       a, b: 1-D distributions of data\n", "       N: number of permutations\n", "    outputs:\n", "       p: p-value, how likely the absolute value of the mean difference occured by chance\n", "    \"\"\"\n", "    # first, compute the shuffled mean differences\n", "    shuffled_distribution = np.zeros(N)\n", "    for i in range(N):\n", "        all_data = np.append(a, b)\n", "        s = np.random.permutation(all_data)\n", "        a_shuffled = s[:len(a)]\n", "        b_shuffled = s[len(a):]\n", "        shuffled_distribution[i] = np.mean(a_shuffled) - np.mean(b_shuffled)\n", "    \n", "    # now compute p\n", "    effective_distribution = np.append(shuffled_distribution, a.mean()-b.mean())\n", "\n", "    total_N = len(effective_distribution)\n", "    greater_equal_N = np.sum(np.abs(effective_distribution) >= np.abs(a.mean()-b.mean()))\n", "    p = greater_equal_N / total_N\n", "    \n", "    return p"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now test it out!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_permutation_test(response_small,response_large,100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What happens if I try it with the spont data?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_permutation_test(spont_small,spont_large,100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What happens if you change `N`?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_permutation_test(response_small,response_large,1000)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that the estimate of p is smaller, basically at the lowest possible value that can be obtained for this number of permutations, N. How maybe permuations does it take to get a p that's not the minimum? Is it worth finding out?\n", "\n", "So rule of thumb: Perform as many permutations as you need to get a **stable** p value. Once p is not the minimum, it will not get much smaller with larger N. You can try that with the spont data "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_permutation_test(spont_small,spont_large,10000)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To get a really small p, you need to perform a lot of permutations. For really big data sets, the computation can be very slow (and unnecessary) for large N."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"6568c72a-e3f7-44b3-90a5-42f764499447\"></a>\n# Permutation test for an arbitrary measurement\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "What if you want to test significance of something besides a mean. How do you do that?  One option is to permute!\n", "\n", "<a id=\"317812bc-5e59-4a28-a6c9-69df0c6b7946\"></a>\n## Correlation coefficient\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Notice that the pupil and spike data are both continuously varying. Maybe we want to measure the correlation coefficient between them, rather than the mean difference between two somewhat arbitrary groups."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(mean_pupil_per_trial, response);\n", "plt.xlabel('pupil size')\n", "plt.ylabel('spikes/sec')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can use `np.corrcoef` to measure a correlation coefficient. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.corrcoef(mean_pupil_per_trial, response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Kind of randomly, this returns a matrix, with the autocorrelation of each signal on the diagonal and the correlation between them in the off-diagonals. There is a reason for this, but for today's purposes, let's just grab the relevant number:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cc = np.corrcoef(mean_pupil_per_trial, response)[0,1]\n", "print(\"correlation between pupil and spike rate:\", np.round(cc,3))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"9ab41349-5145-4fba-850e-f32a48f134f3\"></a>\n## Generate a custom metric function\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "In our test we have been measuring the significance of absolute mean difference. (Note in passing that if you don't use `abs`, you can perform one-tailed test.) Let's make a function that computes the absolute mean difference in one step:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def my_absolute_mean_difference(a,b):\n", "    \"\"\"\n", "    Helper function for flexible_permutation_test, compute the absolute mean difference between a and b\n", "    \"\"\"\n", "    m = np.abs(a.mean()-b.mean())\n", "    return m\n", "\n", "my_absolute_mean_difference(response_small, response_large)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Simply executing `my_absolute_mean_difference` will give you some useuful information."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_absolute_mean_difference"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And you can ask for help, same as for the funciton above."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_absolute_mean_difference?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Why do this? Cool thing about Python (and many other languages), you can pass a function as a parameter into another function. So now we can write a permutation test that evaluates an abitrary statistic. Let's modify the function from above. We replace the calls to `np.mean()` with a new parameter `myfunc`. \n", "\n", "This function is turning into something of a beast, but you should be able to figure out what's going on."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def flexible_permutation_test(a, b, myfunc, N=100, verbose=False):\n", "    \"\"\"\n", "    Permutation to test whether the the value of myfunc(a,b) is significantly greater \n", "    than expected by chance.\n", "    inputs:\n", "       a, b: 1-D distributions of data\n", "       myfunc: user-defined function such that stat=myfunc(a,b) returns a scalar value\n", "            stat, which can be evaluated over permutations of a and b\n", "       N: number of permutations\n", "       verbose: plot a histrogram of the shuffled data, helpful for debugging.\n", "    outputs:\n", "       p: p-value, how likely the actual value occurred by chance\n", "    \"\"\"\n", "    # first, compute the shuffled mean differences\n", "    shuffled_distribution = np.zeros(N)\n", "    for i in range(N):\n", "        all_data = np.append(a, b)\n", "        s = np.random.permutation(all_data)\n", "        a_shuffled = s[:len(a)]\n", "        b_shuffled = s[len(a):]\n", "        shuffled_distribution[i] = myfunc(a_shuffled,b_shuffled)\n", "    \n", "    # now compute p\n", "    actual_value = myfunc(a,b)\n", "    effective_distribution = np.append(shuffled_distribution, actual_value)\n", "\n", "    total_N = len(effective_distribution)\n", "    # Note that we don't use absolute values here because we want to leave \n", "    # flexibility around one- vs. two-tailed tests\n", "    greater_equal_N = np.sum(effective_distribution >= actual_value)\n", "    p = greater_equal_N / total_N\n", "    \n", "    if verbose:\n", "        plt.figure()\n", "        plt.hist(shuffled_distribution, label='shuffled')\n", "        plt.axvline(actual_value, color='r', label='acutal')\n", "        plt.xlabel('statistic')\n", "        plt.ylabel('count')\n", "        plt.legend()\n", "        \n", "    return p"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we pass `my_absolute_mean_difference` to this new function."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flexible_permutation_test(response_small, response_large, my_absolute_mean_difference, N=100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice the `verbose` option. What does that do?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "flexible_permutation_test(response_small, response_large, my_absolute_mean_difference, \n", "                          N=100, verbose=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"a48a1233-3876-4811-a1a1-b334b11a5757\"></a>\n## Exercise 10: custom correlation coefficient function\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Now, define a function `my_correlation_coefficient` that returns the correlation coefficient as a single number (ie, the relevant entry in the matrix returned by `np.corrcoef`). Copying the format from the `def` of `my_absolute_mean_difference`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Answer\n", "def my_correlation_coefficient(a,b):\n", "    \"\"\"\n", "    compute the correlation coefficient between a and b.\n", "    \"\"\"\n", "    cc = np.corrcoef(a, b)[0,1]\n", "    return cc"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now test it here:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_correlation_coefficient(mean_pupil_per_trial, response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And now, try passing it to `flexible_permutation_test`!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flexible_permutation_test(mean_pupil_per_trial, response, my_correlation_coefficient, N=100, verbose=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And you can try the same thing for `spont`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flexible_permutation_test(mean_pupil_per_trial, spont, my_correlation_coefficient, 100, True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["... or even for the raw traces! Pay attention to values on the $x$-axis. Notice that the overall correlation in this case is smaller (because of noise), but the correlation of the shuffled data is tiny."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flexible_permutation_test(pupil.flatten(), spikes.flatten(), \n", "                          my_correlation_coefficient, 100, True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"78c5bbbe-3a72-4113-ac99-d7336804899a\"></a>\n# Existing resources for permutation statistics\n<a href=\"#Overview\">Return to overview</a>\n", "\n", "Note that for comparisons of mean, like the one described above, there are built-in functions, along with a bunch of other more sophisticated tests, in `scipy.stats`.\n", "\n", "For example, a Student's T test can be peformed with permutations, giving very similar results to our permutation test. (The 0.0 pvalue indicates that "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Evoked:\", ss.ttest_ind(response_small, response_large, permutations=1000))\n", "print(\"Spont:\",ss.ttest_ind(spont_small, spont_large, permutations=1000))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The Wilcoxon signed-rank test does the same thing, more or less, for medians."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Evoked:\", ss.wilcoxon(response_small, response_large))\n", "print(\"Spont:\",ss.wilcoxon(spont_small, spont_large))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.1"}}, "nbformat": 4, "nbformat_minor": 4}