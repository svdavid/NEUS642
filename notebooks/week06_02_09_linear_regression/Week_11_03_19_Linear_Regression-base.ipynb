{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz8ufD1MsrPK"
   },
   "source": [
    "# Week 11 - Linear Regression\n",
    "\n",
    "**What Is Regression?**\n",
    "\n",
    "In statistics, regression is a method used for modeling the relationship between a dependent variable and one or more independent variables. The goal of regression analysis is to understand how the independent variables impact the dependent variable and to predict the value of the dependent variable based on the values of the independent variables.\n",
    "\n",
    "**When Do You Need Regression?**\n",
    "\n",
    "Typically, regression is used to answer whether and how some phenomenon influences the other or how several variables are related, and the strength and direction of that relationship. . For example, you can use it to determine if and to what extent experience or gender impacts salaries.\n",
    "\n",
    "Regression is also useful when you want to forecast a response using a new set of predictors. For example, you could use it to study the relationship between brain activity and memory performance.\n",
    "\n",
    "**What is Linear Regression?**\n",
    "\n",
    "In statistics, linear regression is a statistical model which estimates the linear relationship between a scalar response and one or more explanatory variables.\n",
    "\n",
    "Linear regression calculates the estimators of the regression coefficients or simply the predicted weights, denoted with ùëè‚ÇÄ, ùëè‚ÇÅ, ‚Ä¶, ùëè·µ£. These estimators define the estimated regression function ùëì(ùê±) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ‚ãØ + ùëè·µ£ùë•·µ£. This function should capture the dependencies between the inputs and output sufficiently well.\n",
    "\n",
    "The estimated or predicted response, ùëì(ùê±·µ¢), for each observation ùëñ = 1, ‚Ä¶, ùëõ, should be as close as possible to the corresponding actual response ùë¶·µ¢. The differences ùë¶·µ¢ - ùëì(ùê±·µ¢) for all observations ùëñ = 1, ‚Ä¶, ùëõ, are called the residuals. Regression is about determining the best predicted weights‚Äîthat is, the weights corresponding to the smallest residuals.\n",
    "\n",
    "To get the best weights, you usually minimize the sum of squared residuals (SSR) for all observations ùëñ = 1, ‚Ä¶, ùëõ: SSR = Œ£·µ¢(ùë¶·µ¢ - ùëì(ùê±·µ¢))¬≤. This approach is called the method of ordinary least squares.\n",
    "\n",
    "**Regression Performance**\n",
    "\n",
    "The variation of actual responses ùë¶·µ¢, ùëñ = 1, ‚Ä¶, ùëõ, occurs partly due to the dependence on the predictors ùê±·µ¢. However, there‚Äôs also an additional inherent variance of the output.\n",
    "\n",
    "The coefficient of determination, denoted as ùëÖ¬≤, tells you which amount of variation in ùë¶ can be explained by the dependence on ùê±, using the particular regression model. A larger ùëÖ¬≤ indicates a better fit and means that the model can better explain the variation of the output with different inputs.\n",
    "\n",
    "The value ùëÖ¬≤ = 1 corresponds to SSR = 0. That‚Äôs the perfect fit, since the values of predicted and actual responses fit completely to each other.\n",
    "\n",
    "The case of one explanatory variable is called simple linear regression.\n",
    "\n",
    "**Simple Linear Regression**\n",
    "\n",
    "Simple or single-variate linear regression is the simplest case of linear regression, as it has a single independent variable, ùê± = ùë•.\n",
    "\n",
    "The following figure illustrates simple linear regression:\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/fig-lin-reg.a506035b654a.png\" alt=\"Description of image\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktLaJVoLuUGs"
   },
   "source": [
    "##Simple Linear Regression with scikit-learn\n",
    "\n",
    "**Step 1: Import packages and classes**\n",
    "\n",
    "The first step is to import the package numpy and the class LinearRegression from sklearn.linear_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmEfuNfru_ty"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xK1Mu4Y7vhgi"
   },
   "source": [
    "**Step 2: Provide data**\n",
    "\n",
    "The second step is defining data to work with. The inputs (regressors, ùë•) and output (response, ùë¶) should be arrays or similar objects. This is the simplest way of providing data for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7YBQJ5Fvj1m"
   },
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 30, 35, 45]).reshape((-1, 1))\n",
    "y = np.array([6, 28, 11, 39, 20, 52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkO8Z7oiv7i6"
   },
   "source": [
    "You should call¬†.reshape()¬†on¬†x¬†because this array must be¬†two-dimensional, or more precisely, it must have¬†one column¬†and¬†as many rows as necessary. That‚Äôs what the argument¬†(-1, 1)¬†of¬†.reshape()¬†specifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rB6PnOr8knsw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "2NluQxjf13oE",
    "outputId": "8e5c7e96-5250-4b21-e599-905ae1663058"
   },
   "outputs": [],
   "source": [
    "# Plotting the data points\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Dummy data for regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buKP29NOwJHI"
   },
   "source": [
    "**Step 3: Create a model and fit it**\n",
    "\n",
    "The next step is to create a linear regression model and fit it using the existing data.\n",
    "\n",
    "Create an instance of the class LinearRegression, which will represent the regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZZAbnUOwMAc"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzySm5IewONr"
   },
   "source": [
    "This statement creates the variable model as an instance of LinearRegression. You can provide several optional parameters to LinearRegression:\n",
    "\n",
    "*   fit_intercept is a Boolean that, if True, decides to calculate the intercept ùëè‚ÇÄ or, if False, considers it equal to zero. It defaults to True.\n",
    "*   normalize is a Boolean that, if True, decides to normalize the input variables. It defaults to False, in which case it doesn‚Äôt normalize the input variables.\n",
    "*   copy_X is a Boolean that decides whether to copy (True) or overwrite the input variables (False). It‚Äôs True by default.\n",
    "*   n_jobs is either an integer or None. It represents the number of jobs used in parallel computation. It defaults to None, which usually means one job. -1 means to use all available processors.\n",
    "\n",
    "Our model as defined above uses the default values of all parameters.\n",
    "\n",
    "It‚Äôs time to start using the model. First, we need to call .fit() on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "Zj71q4N2wy9f",
    "outputId": "0581bf4c-1e07-4b35-e167-9ed2d675d6ab"
   },
   "outputs": [],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyNFOBd7xDzD"
   },
   "source": [
    "With .fit(), you calculate the optimal values of the weights ùëè‚ÇÄ and ùëè‚ÇÅ, using the existing input and output, x and y, as the arguments. In other words, .fit() fits the model. It returns self, which is the variable model itself. We can combine the last two statements into this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6SOVrsLxE52"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WvY0GXvxwN9"
   },
   "source": [
    "**Step 4: Get results**\n",
    "\n",
    "Once you have your model fitted, you can get the results to check whether the model works satisfactorily and to interpret it.\n",
    "\n",
    "You can obtain the coefficient of determination, ùëÖ¬≤, with .score() called on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "od7qYDf3yhi8",
    "outputId": "846229d6-c5cb-48ce-815f-441298488b0b"
   },
   "outputs": [],
   "source": [
    "r_sq = model.score(x, y)\n",
    "(f\"coefficient of determination: {r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcbSedndzEax"
   },
   "source": [
    "When you‚Äôre applying .score(), the arguments are also the predictor x and response y, and the return value is ùëÖ¬≤.\n",
    "\n",
    "The attributes of the model are .intercept_, which represents the intercept, and .coef_, which represents the slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBkREt45zUih",
    "outputId": "4ea6a688-f918-4dfe-e0bb-d88db7a13c07"
   },
   "outputs": [],
   "source": [
    "print(f\"intercept: {model.intercept_}\")\n",
    "print(f\"slope: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3MN4Qtyzg7I"
   },
   "source": [
    "This illustrates that your model predicts the response 5.63 when ùë• is zero. The value slope means that the predicted response rises by 0.54 when ùë• is increased by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HywxEfBRzrWC"
   },
   "source": [
    "**Step 5: Predict response**\n",
    "\n",
    "Once you have a satisfactory model, then you can use it for predictions with either existing or new data. To obtain the predicted response, use .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYsbcssh0BUQ",
    "outputId": "e9bd0578-cdcc-499a-f26e-17d1f18f01da"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os33PGJa0MAV"
   },
   "source": [
    "You can also use fitted models to calculate the outputs based on new inputs:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyeAPjsx0Oc3",
    "outputId": "e0c79072-083e-4008-fb7e-98ec25eae8f8"
   },
   "outputs": [],
   "source": [
    "x_new = np.arange(5).reshape((-1, 1))\n",
    "x_new\n",
    "\n",
    "y_new = model.predict(x_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EoiqdAZ1Ube"
   },
   "source": [
    "Here .predict() is applied to the new regressor x_new and yields the response y_new. This example conveniently uses arange() from numpy to generate an array with the elements from 0, inclusive, up to but excluding 5‚Äîthat is, 0, 1, 2, 3, and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bx6tBJwe1WVm"
   },
   "source": [
    "**Plotting the data points**\n",
    "\n",
    "You can also visualize linear regression on a plot!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "DikpFQLZknsy",
    "outputId": "8e5c7e96-5250-4b21-e599-905ae1663058"
   },
   "outputs": [],
   "source": [
    "# Plotting the data points\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Plotting the linear regression line\n",
    "plt.plot(x, model.predict(x), \"r-\")\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression with Numpy and model.fit()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Sl3KvJCKEYw"
   },
   "source": [
    "Your turn! Let's try this now with a real dataset! We will be using a simple dataset to implement this algorithm. This dataset contains Head Size (cm^3) and Brain Weight (grams) where Head Size is an independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d7y-j9DMc7u"
   },
   "source": [
    "Let's begin going through the steps of doing a simple linear regression with the data.\n",
    "\n",
    "## Exercise 1 -  Import packages and classes\n",
    "\n",
    "As we did above, the first step is to import the package numpy and the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qrOcrVDM9-S"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csuieBvxNBnF"
   },
   "source": [
    "## Excercise 2 -  Provide data\n",
    "\n",
    "Next, you want to load the data from the file `head_brain_dataset.csv` into an array called `head_brain_data`. Remember that numpy is expecting an array. Additionally, assign the independent and dependent variables to `x` and `y`, whic respectively are the 2nd and 3rd columns of the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iJlu_93knsy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "datafile = os.path.join('simple_linear_regression_sample_data','head_brain_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEXPWPDVPLzk"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "head_brain_data = np.loadtxt(datafile, delimiter=',', skiprows=1)\n",
    "x=head_brain_data[:, 2].reshape((-1, 1))\n",
    "y=head_brain_data[:, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25JMkn77PjK6"
   },
   "source": [
    "We can get a quick sense of the dataset‚Äôs dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZ7OJaXfPktl",
    "outputId": "5a40fc8d-59fd-4b87-a3f1-4081da5dfd19"
   },
   "outputs": [],
   "source": [
    "head_brain_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6f7td94P12-"
   },
   "source": [
    "Let's look at the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLqptqqDP84-",
    "outputId": "741da05c-d8f1-4d76-b106-9b435362d735"
   },
   "outputs": [],
   "source": [
    "print(head_brain_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFgZQflNCyAo"
   },
   "source": [
    "## Exercise 3 - Create a model and fit it\n",
    "\n",
    "Next, create a linear regression model and fit it using the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebx_GY9lIWcc"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtaCF9cqI3h7"
   },
   "source": [
    "## Exercise 4: Get results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-eCsIfnJDB4"
   },
   "source": [
    "Now that we have our model fitted, we can get the results to check whether the model works satisfactorily and to interpret it.\n",
    "\n",
    "Next, calculate the coefficient of determination (ùëÖ¬≤), the intercept, and the slope.\n",
    "\n",
    "Hint: .score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j86i4cZFJX_1",
    "outputId": "3fc0e07c-b44f-4177-ed01-1c62887b3244"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "r_sq = model.score(x, y)\n",
    "(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "print(f\"slope: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2citOCEZJnQn"
   },
   "source": [
    "## Exercise 5: Predict response\n",
    "\n",
    "Now that we have a satisfactory model, we can use it for predictions with our data. Calculate the predicted response.\n",
    "\n",
    "Hint: `.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlYlEhrvKAW-",
    "outputId": "ce619d19-a251-477a-a904-0ea01074bd02"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfTU9REgKTvO"
   },
   "source": [
    "## Exercise 6: Plotting the data points\n",
    "\n",
    "Plot the data points so that we can visualize this linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "U7s62mZOKkXy",
    "outputId": "ebc96a2b-8239-443e-8ea5-df34b79d060e"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# Plotting the data points\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Plotting the linear regression line\n",
    "plt.plot(x, model.predict(x), \"r-\")\n",
    "\n",
    "plt.xlabel('Head Size (cm^3)')\n",
    "plt.ylabel('Brain Weight (grams)')\n",
    "plt.title('Linear Regression with Numpy and model.fit()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1Jx7GqHANfb"
   },
   "source": [
    "# Multiple Linear Regression With scikit-learn\n",
    "\n",
    "You can implement multiple linear regression following the same steps as you would for simple regression. The main difference is that your x array will now have two or more columns.\n",
    "\n",
    "\n",
    "*  Steps 1 and 2: Import packages and classes, and provide data\n",
    "\n",
    "First, you import numpy and sklearn.linear_model.LinearRegression and provide known inputs and output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ArhVtUiBJH7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# define the data set\n",
    "x = [\n",
    "    [0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]\n",
    "]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "\n",
    "# Convert the dataset into NumPy arrays\n",
    "x, y = np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpBaAIbHCf66"
   },
   "source": [
    "Now let's print out x and y and see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOaPmNQ8CmHE",
    "outputId": "ce3766ce-45ae-4321-ed6d-e7b92ddf1bfa"
   },
   "outputs": [],
   "source": [
    "# Print out the values of x and y with labels\n",
    "print(\"x =\", x)\n",
    "print(\"y =\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJzuG9q_DII-"
   },
   "source": [
    "In multiple linear regression, x is a two-dimensional array with at least two columns, while y is usually a one-dimensional array. This is a simple example of multiple linear regression, and x has exactly two columns.\n",
    "\n",
    "now for  \n",
    "\n",
    "*   step 3: Create a model and fit it.\n",
    "\n",
    "The next step is to create the regression model as an instance of LinearRegression and fit it with .fit():\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iagIXXiEDlr"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1GZ9VyjEJn1"
   },
   "source": [
    "The result of this statement is the variable model referring to the object of type LinearRegression. It represents the regression model fitted with existing data.\n",
    "\n",
    "*  Step 4: Get results.\n",
    "\n",
    "## Exercise 7 - get results\n",
    "\n",
    "Obtain the properties of the model the same way as in the case of simple linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWOD0NWmEdbE",
    "outputId": "94267b8e-7208-4b3c-ebc3-aff7859b728d"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "r_sq = model.score(x, y)\n",
    "\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "\n",
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IC6GeU6gE5rg"
   },
   "source": [
    "You obtain the value of ùëÖ¬≤ using .score() and the values of the estimators of regression coefficients with .intercept_ and .coef_. Again, .intercept_ holds the bias ùëè‚ÇÄ, while now .coef_ is an array containing ùëè‚ÇÅ and ùëè‚ÇÇ.\n",
    "\n",
    "In this example, the intercept is approximately 5.52, and this is the value of the predicted response when ùë•‚ÇÅ = ùë•‚ÇÇ = 0. An increase of ùë•‚ÇÅ by 1 yields a rise of the predicted response by 0.45. Similarly, when ùë•‚ÇÇ grows by 1, the response rises by 0.26.\n",
    "\n",
    "*   Step 5: Predict response\n",
    "\n",
    "Predictions also work the same way as in the case of simple linear regression:\n",
    "\n",
    "## Excersise 8 - generate prediction\n",
    "\n",
    "Remember how did we make prediction in linear regression?\n",
    "try using the function \" model.predict()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2UmMPh8FTAL",
    "outputId": "3f262d86-0b14-4407-e9c6-97513be55726"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wez0JSnfGO03"
   },
   "source": [
    "The predicted response is obtained with .predict(), but there is another way to obtain the prediction as the following example:\n",
    "\n",
    "  Here, we predict the output values by multiplying each column of the input with the appropriate weight, summing the results, and adding the intercept to the sum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0brwsnQGPju",
    "outputId": "5555eabc-b2ae-461f-fbcf-32c0f8b9aa8b"
   },
   "outputs": [],
   "source": [
    "y_pred = model.intercept_ + np.sum(model.coef_ * x, axis=1)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-X31rLWIS83"
   },
   "source": [
    "Now let's apply this model to new data. Create an array of numbers from 0 to 9, incrementing by 1.  Then reshape the array into a 2D array with 2 columns. The -1 in the reshape function means that NumPy will automatically determine the number of rows based on the total number of elements in the array. Since there are 10 elements in the array and 2 columns specified, the resulting shape will be (5, 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOu_b3BSHPKF",
    "outputId": "f5b1348c-a6ed-4abb-9d3e-81a6f0688b1b"
   },
   "outputs": [],
   "source": [
    "x_new = np.arange(10).reshape((-1, 2))\n",
    "print('new x:', x_new)\n",
    "\n",
    "y_new = model.predict(x_new)\n",
    "print (f\"predicted y:\\n{y_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(x_)\n",
    "plt.figure()\n",
    "plt.plot(x, y, '.', label='data')\n",
    "plt.plot(x, y_predicted, label='fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrxqmefdMBzr"
   },
   "source": [
    "# Polynomial Regression With scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NArmCaPPMHgA"
   },
   "source": [
    "Implementing polynomial regression with scikit-learn is very similar to linear regression. There‚Äôs only one extra step: you need to transform the array of inputs to include nonlinear terms such as ùë•¬≤.\n",
    "\n",
    "Now let's go over the basic steps for implementing polynomial regression using scikit-learn.\n",
    "\n",
    "**Step 1: Import packages and classes**\n",
    "\n",
    "In addition to numpy and sklearn.linear_model.LinearRegression, you should also import the class PolynomialFeatures from sklearn.preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-YwaaC8Zih5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3XS2L3yTn6k"
   },
   "source": [
    "The import is now done, and you have everything you need to work with.\n",
    "\n",
    "Step 2a: Provide data\n",
    "\n",
    "This step defines the input and output and is the same as in the case of linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGDYctZ9Tp3S"
   },
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([15, 11, 2, 8, 25, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSPHdAgGTtJL"
   },
   "source": [
    "Now you have the input and output in a suitable format. Keep in mind that you need the input to be a two-dimensional array. That‚Äôs why .reshape() is used.\n",
    "\n",
    "Step 2b: Transform input data\n",
    "\n",
    "This is the new step that you need to implement for polynomial regression!\n",
    "\n",
    "As you learned earlier, you need to include ùë•¬≤‚Äîand perhaps other terms‚Äîas additional features when implementing polynomial regression. For that reason, you should transform the input array x to contain any additional columns with the values of ùë•¬≤, and eventually more features.\n",
    "\n",
    "It‚Äôs possible to transform the input array in several ways, like using insert() from numpy. But the class PolynomialFeatures is very convenient for this purpose. Go ahead and create an instance of this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMdVrS5nTwU5"
   },
   "outputs": [],
   "source": [
    "transformer = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKhNrEIATzsO"
   },
   "source": [
    "The variable transformer refers to an instance of PolynomialFeatures that you can use to transform the input x.\n",
    "\n",
    "You can provide several optional parameters to PolynomialFeatures:\n",
    "\n",
    "degree is an integer (2 by default) that represents the degree of the polynomial regression function.\n",
    "interaction_only is a Boolean (False by default) that decides whether to include only interaction features (True) or all features (False).\n",
    "include_bias is a Boolean (True by default) that decides whether to include the bias, or intercept, column of 1 values (True) or not (False).\n",
    "This example uses the default values of all parameters except include_bias. You‚Äôll sometimes want to experiment with the degree of the function, and it can be beneficial for readability to provide this argument anyway.\n",
    "\n",
    "Before applying transformer, you need to fit it with .fit():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "vSDiLR3PT4WY",
    "outputId": "1ef2e475-63ae-4e99-eeaa-8a71df4f9fea"
   },
   "outputs": [],
   "source": [
    "transformer.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtfE09r6T7_-"
   },
   "source": [
    "Once transformer is fitted, then it‚Äôs ready to create a new, modified input array. You apply .transform() to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIVmLyArUDFH"
   },
   "outputs": [],
   "source": [
    "x_ = transformer.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHadqUBFT_Zc"
   },
   "source": [
    "That‚Äôs the transformation of the input array with .transform(). It takes the input array as the argument and returns the modified array.\n",
    "\n",
    "You can also use .fit_transform() to replace the three previous statements with only one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlrR8hOYUHQU"
   },
   "outputs": [],
   "source": [
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt6NbanmUKB5"
   },
   "source": [
    "With .fit_transform(), you‚Äôre fitting and transforming the input array in one statement. This method also takes the input array and effectively does the same thing as .fit() and .transform() called in that order. It also returns the modified array. This is how the new input array looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPbsYfChUOpO",
    "outputId": "7a4dba89-27e0-410c-b633-438da34b8040"
   },
   "outputs": [],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ecb6aMUUSEw"
   },
   "source": [
    "The modified input array contains two columns: one with the original inputs and the other with their squares.\n",
    "\n",
    "Step 3: Create a model and fit it\n",
    "\n",
    "This step is also the same as in the case of linear regression. You create and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cVFPJHRUbbt"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0dSHwD8UeD-"
   },
   "source": [
    "The regression model is now created and fitted. It‚Äôs ready for application. You should keep in mind that the first argument of .fit() is the modified input array x_ and not the original x.\n",
    "\n",
    "Step 4: Get results\n",
    "\n",
    "You can obtain the properties of the model the same way as in the case of linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKUDUbBCUe5l",
    "outputId": "3e6d1b84-21f1-4e5e-864d-9f2a58a43c0d"
   },
   "outputs": [],
   "source": [
    "r_sq = model.score(x_, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "\n",
    "\n",
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(x_)\n",
    "plt.figure()\n",
    "plt.plot(x, y, '.', label='data')\n",
    "plt.plot(x, y_predicted, label='fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-aguUmaUhRa"
   },
   "source": [
    "Again, .score() returns ùëÖ¬≤. Its first argument is also the modified input x_, not x. The values of the weights are associated to .intercept_ and .coef_. Here, .intercept_ represents ùëè‚ÇÄ, while .coef_ references the array that contains ùëè‚ÇÅ and ùëè‚ÇÇ.\n",
    "\n",
    "You can obtain a very similar result with different transformation and regression arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwVoPnQYUlUz"
   },
   "outputs": [],
   "source": [
    "x_ = PolynomialFeatures(degree=2, include_bias=True).fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VDnhVxZUnuv"
   },
   "source": [
    "If you call PolynomialFeatures with the default parameter include_bias=True, or if you just omit it, then you‚Äôll obtain the new input array x_ with the additional leftmost column containing only 1 values. This column corresponds to the intercept. This is how the modified input array looks in this case:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iNqq-n0UqMh",
    "outputId": "9be2ab2a-08e5-4fb7-b5c2-16bb41bacb79"
   },
   "outputs": [],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sVa-bykUsVf"
   },
   "source": [
    "The first column of x_ contains ones, the second has the values of x, while the third holds the squares of x.\n",
    "\n",
    "The intercept is already included with the leftmost column of ones, and you don‚Äôt need to include it again when creating the instance of LinearRegression. Thus, you can provide fit_intercept=False. This is how the next statement looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukY5dIoBUvN3"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False).fit(x_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqDuHEuhUyEc"
   },
   "source": [
    "The variable model again corresponds to the new input array x_. Therefore, x_ should be passed as the first argument instead of x.\n",
    "\n",
    "This approach yields the following results, which are similar to the previous case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U00eQxb7U0YV",
    "outputId": "480706df-2c05-48d2-a509-a45dcc041dcf"
   },
   "outputs": [],
   "source": [
    "r_sq = model.score(x_, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "\n",
    "\n",
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(x_)\n",
    "plt.figure()\n",
    "plt.plot(x, y, '.', label='data')\n",
    "plt.plot(x, y_predicted, label='fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC8oK1scU29b"
   },
   "source": [
    "You see that now .intercept_ is zero, but .coef_ actually contains ùëè‚ÇÄ as its first element. Everything else is the same.\n",
    "\n",
    "Step 5: Predict response\n",
    "\n",
    "If you want to get the predicted response, just use .predict(), but remember that the argument should be the modified input x_ instead of the old x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kS28Q_elU-Ic",
    "outputId": "a7666761-fe3a-4d9f-9bb2-c8c5fadd40af"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKuTLRjMU6xu"
   },
   "source": [
    "As you can see, the prediction works almost the same way as in the case of linear regression. It just requires the modified input instead of the original.\n",
    "\n",
    "You can apply an identical procedure if you have several input variables. You‚Äôll have an input array with more than one column, but everything else will be the same. Here‚Äôs an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "133mlssVVBkp"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import packages and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2a: Provide data\n",
    "x = [\n",
    "  [0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]\n",
    "]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "# Step 2b: Transform input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "# Step 3: Create a model and fit it\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Step 4: Get results\n",
    "r_sq = model.score(x_, y)\n",
    "intercept, coefficients = model.intercept_, model.coef_\n",
    "\n",
    "# Step 5: Predict response\n",
    "y_pred = model.predict(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXhAsIJ6VJYV"
   },
   "source": [
    "This regression example yields the following results and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGvok_amVJ7P",
    "outputId": "4d80fced-7ecd-4a33-d38d-38a2b7969a9c"
   },
   "outputs": [],
   "source": [
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "\n",
    "print(f\"intercept: {intercept}\")\n",
    "\n",
    "\n",
    "print(f\"coefficients:\\n{coefficients}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqjvDmahVJKm"
   },
   "source": [
    "In this case, there are six regression coefficients, including the intercept, as shown in the estimated regression function ùëì(ùë•‚ÇÅ, ùë•‚ÇÇ) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ùëè‚ÇÇùë•‚ÇÇ + ùëè‚ÇÉùë•‚ÇÅ¬≤ + ùëè‚ÇÑùë•‚ÇÅùë•‚ÇÇ + ùëè‚ÇÖùë•‚ÇÇ¬≤.\n",
    "\n",
    "You can also notice that polynomial regression yielded a higher coefficient of determination than multiple linear regression for the same problem. At first, you could think that obtaining such a large ùëÖ¬≤ is an excellent result. It might be.\n",
    "\n",
    "However, in real-world situations, having a complex model and ùëÖ¬≤ very close to one might also be a sign of overfitting. To check the performance of a model, you should test it with new data‚Äîthat is, with observations not used to fit, or train, the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4uWm1wHXs6l"
   },
   "source": [
    "# Perform polynomial regression on EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L9hjVJMuw6C"
   },
   "source": [
    "Here we come, a real life-ish example~\n",
    "We will be applying polynomial regression to analyze a 1-second long EEG data extracted from the file eeg_data_new.csv.\n",
    "EEG, or Electroencephalogram, records the electrical activity of the brain over time, typically capturing complex and dynamic patterns. But what can polynomial regression do to EEG data? Firstly, it enables us to recognize and extract complex patterns that may not be adequately captured by linear models. Secondly, polynomial regression can help in reconstructing noisy or missing data points within the EEG signal, providing a smoother representation of brain activity. Additionally, polynomial regression serves as a valuable tool for feature extraction, deriving higher-order features from the original EEG data, which may contain crucial information for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfEnnWbxvXtr"
   },
   "source": [
    "## Exercise - polynomial regression with real data\n",
    "\n",
    "We are going to fit a polynomial regression model to the eeg data. let's recall the steps we will need to take:\n",
    "\n",
    "\n",
    "*   Step 1: load the data.\n",
    "*   Step 2: Prepare the data for polynomial regression.  \n",
    "*   Step 3: Fit the polynomial regression model\n",
    "*   Step 4: Evaluate the model.\n",
    "*   Step 5: Visualize the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A77AvoRWPjOK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph0OCd98PmGH"
   },
   "source": [
    "Step 1: Load the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30DrZ_DGP00C"
   },
   "outputs": [],
   "source": [
    "eeg_data = pd.read_csv(\"eeg_data_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLemgV9lP65O"
   },
   "source": [
    "Step 2: Prepare the data for polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DywdceDP7kC"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "X = eeg_data['time'].values.reshape(-1, 1)  # Independent variable (time)\n",
    "y = eeg_data['amplitude'].values            # Dependent variable (amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJd_waEhQANA"
   },
   "source": [
    "Step 3: Fit the polynomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "XCXl0QtwQB9n",
    "outputId": "602684d8-6536-494c-9eeb-90c9f8268a7e"
   },
   "outputs": [],
   "source": [
    "degree = 50  # Degree of the polynomial, you can adjust it\n",
    "# Answer\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73S7-x32QM0c"
   },
   "source": [
    "Step 4: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVPPIvI3QY5H",
    "outputId": "71b99704-8bf0-442e-a580-ef654d11985d"
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = model.predict(X_poly)  # Predicted values\n",
    "r_squared = r2_score(y, y_pred)\n",
    "r_sq = model.score(X_poly, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S56QCR2tQgtm"
   },
   "source": [
    "Step 5: Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "ag_BiIuQX2Z5",
    "outputId": "12ceed9a-2f37-49f0-be45-658114bdfdfe"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color='blue', label='Data')\n",
    "plt.plot(X, model.predict(X_poly), color='red', label='Polynomial Regression')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Polynomial Regression on EEG Data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbBKCcLax1Qr"
   },
   "source": [
    "Is your polynomial regression present a underfit or a overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRzBn3XLAPZ2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IO2-W6LD2q5X"
   },
   "source": [
    "# Polynomial Regression With statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azOMUk8m2tvc"
   },
   "source": [
    "You can implement linear regression in Python by using the package statsmodels as well. Typically, this is desirable when you need more detailed results.\n",
    "\n",
    "The procedure is similar to that of scikit-learn. We will keep working on the eeg data that we used in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPKMfsZu2-p_"
   },
   "source": [
    "**Step 1: Import packages**\n",
    "\n",
    "First you need to do some imports. In addition to numpy, you need to import statsmodels.api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Iz69U3L3ETY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntME9OT73Jxs"
   },
   "source": [
    "**Step 2: Provide data and transform inputs**\n",
    "\n",
    "You can provide the inputs and outputs the same way as you did when you were using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWNEbFSx3NG9"
   },
   "outputs": [],
   "source": [
    "# Load the EEG data from the CSV file\n",
    "eeg_data = pd.read_csv('eeg_data_new.csv')\n",
    "\n",
    "# Prepare the data for polynomial regression\n",
    "X = eeg_data['time']  # Independent variable (time)\n",
    "y = eeg_data['amplitude']  # Dependent variable (amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NehRZy9g3y8T"
   },
   "source": [
    "The input and output arrays are created, but the job isn‚Äôt done yet.\n",
    "\n",
    "You need to add the column of ones to the inputs if you want statsmodels to calculate the intercept ùëè‚ÇÄ. It doesn‚Äôt take ùëè‚ÇÄ into account by default. This is just one function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uo-ZQs2V3371"
   },
   "outputs": [],
   "source": [
    "# Add a constant to the independent variable for the intercept term\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_N-EOfu39QL"
   },
   "source": [
    "Step 3: Create a model and fit it\n",
    "\n",
    "The regression model based on ordinary least squares is an instance of the class statsmodels.regression.linear_model.OLS. This is how you can obtain one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWc_dI1s4SWc"
   },
   "outputs": [],
   "source": [
    "# Fit the polynomial regression model (e.g., polynomial of degree 3)\n",
    "degree = 30\n",
    "poly = sm.OLS(y, np.column_stack([X**i for i in range(degree+1)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4omRbjt4WwO"
   },
   "source": [
    "You should be careful here! Notice that the first argument is the output, followed by the input. This is the opposite order of the corresponding scikit-learn functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcxbOweP4ngI"
   },
   "source": [
    "Once your model is created, then you can apply .fit() on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ho-tzKdq4i_j"
   },
   "outputs": [],
   "source": [
    "result = poly.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb0lHAGx4pik"
   },
   "source": [
    "By calling .fit(), you obtain the variable results, which is an instance of the class statsmodels.regression.linear_model.RegressionResultsWrapper. This object holds a lot of information about the regression model.\n",
    "\n",
    "**Step 4: Get results**\n",
    "\n",
    "The variable results refers to the object that contains detailed information about the results of linear regression. Explaining these results is far beyond the scope of this tutorial, but you‚Äôll learn here how to extract them.\n",
    "\n",
    "You can call .summary() to get the table with the results of linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvQpamOq4tfr",
    "outputId": "958bf3f3-a877-4e97-ea3b-05b7a752f6c8"
   },
   "outputs": [],
   "source": [
    "# Print the summary of the regression results\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv3lFkoc448d"
   },
   "source": [
    "This table is very comprehensive. You can find many statistical values associated with linear regression, including ùëÖ¬≤, ùëè‚ÇÄ, ùëè‚ÇÅ, and ùëè‚ÇÇ.\n",
    "\n",
    "In this particular case, you might obtain a warning saying kurtosistest only valid for n>=20. This is due to the small number of observations provided in the example.\n",
    "\n",
    "You can extract any of the values from the table above. Here‚Äôs an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVz4N9Rv4_I1",
    "outputId": "ce17557e-9fb7-43c1-dd11-37a5e8999d16"
   },
   "outputs": [],
   "source": [
    "print(f\"coefficient of determination: {result.rsquared}\")\n",
    "\n",
    "\n",
    "print(f\"adjusted coefficient of determination: {result.rsquared_adj}\")\n",
    "\n",
    "\n",
    "print(f\"regression coefficients: {result.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrZweOdo5LeZ"
   },
   "source": [
    "That‚Äôs how you obtain some of the results of linear regression:\n",
    "\n",
    ".rsquared holds ùëÖ¬≤.\n",
    ".rsquared_adj represents adjusted ùëÖ¬≤‚Äîthat is, ùëÖ¬≤ corrected according to the number of input features.\n",
    ".params refers the array with ùëè‚ÇÄ, ùëè‚ÇÅ, and ùëè‚ÇÇ.\n",
    "You can also notice that these results are identical to those obtained with scikit-learn for the same problem.\n",
    "\n",
    "**Step 5: Predict response**\n",
    "\n",
    "You can obtain the predicted response on the input values used for creating the model using .fittedvalues or .predict() with the input array as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKn5A0Wg5Q6V",
    "outputId": "48e2e364-99c3-4a7d-92bd-17c167fd5062"
   },
   "outputs": [],
   "source": [
    "# Predict the values using the fitted model\n",
    "y_pred = result.predict()\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3aji30R53J_"
   },
   "source": [
    "**Step 6: Vidualize the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "iIvP0L8D6KGk",
    "outputId": "5e73cbe8-4f9a-460f-99b8-414ee847a317"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.scatter(X['time'], y, color='blue', label='Data')\n",
    "plt.plot(X['time'], y_pred, color='red', label='Polynomial Regression')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Polynomial Regression using Statsmodels')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
